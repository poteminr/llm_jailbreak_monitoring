{
    "datasets": [
        {
            "dataset_path": "unalignment/toxic-dpo-v0.2",
            "prompt_field": "prompt",
            "output_field": "chosen",
            "label_field": null,
            "jailbreak_field": null,
            "dataset_name": null
        },
        {
            "dataset_path": "unalignment/toxic-dpo-v0.1",
            "prompt_field": "prompt",
            "output_field": "chosen",
            "label_field": null,
            "jailbreak_field": null,
            "dataset_name": null
        },
        {
            "dataset_path": "lmsys/toxic-chat",
            "prompt_field": "user_input",
            "output_field": null,
            "label_field": null,
            "jailbreak_field": "jailbreaking",
            "dataset_name": "toxicchat0124"
        },
        {
            "dataset_path": "rubend18/ChatGPT-Jailbreak-Prompts",
            "prompt_field": "Prompt",
            "output_field": null,
            "label_field": null,
            "jailbreak_field": "Jailbreak Score",
            "dataset_name": null
        },
        {
            "dataset_path": "JailbreakBench/JBB-Behaviors",
            "prompt_field": "Goal",
            "output_field": null,
            "label_field": null,
            "jailbreak_field": "Category",
            "dataset_name": "behaviors"
        },
        {
            "dataset_path": "JailbreakBench/JBB-Behaviors",
            "prompt_field": "prompt",
            "output_field": null,
            "label_field": null,
            "jailbreak_field": "target_responce",
            "dataset_name": "judge_comparison"
        }
    ]
}